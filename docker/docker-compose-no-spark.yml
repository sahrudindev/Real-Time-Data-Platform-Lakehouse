# =============================================================================
# ENTERPRISE DATA PLATFORM - DOCKER COMPOSE (WITHOUT SPARK)
# =============================================================================
# Running without Spark services due to image availability issues
# You can run Spark separately using local Python installation
# =============================================================================

networks:
  data-platform:
    driver: bridge
    name: enterprise-data-platform

volumes:
  postgres-data:
  minio-data:
  elasticsearch-data:
  metabase-postgres-data:
  prometheus-data:
  grafana-data:
  redis-data:
  delta-data:

services:
  # ===========================================================================
  # MESSAGE BROKER - ZOOKEEPER
  # ===========================================================================
  zookeeper:
    image: confluentinc/cp-zookeeper:7.5.0
    container_name: zookeeper
    hostname: zookeeper
    ports:
      - "2181:2181"
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
      ZOOKEEPER_INIT_LIMIT: 5
      ZOOKEEPER_SYNC_LIMIT: 2
    healthcheck:
      test: ["CMD", "nc", "-z", "localhost", "2181"]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - data-platform
    restart: unless-stopped

  # ===========================================================================
  # MESSAGE BROKER - KAFKA
  # ===========================================================================
  kafka:
    image: confluentinc/cp-kafka:7.5.0
    container_name: kafka
    hostname: kafka
    ports:
      - "9093:9092"
      - "29092:29092"
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092,PLAINTEXT_HOST://localhost:29092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: 'false'
      KAFKA_LOG_RETENTION_HOURS: 168
      KAFKA_LOG_RETENTION_BYTES: 1073741824
      KAFKA_MESSAGE_MAX_BYTES: 10485760
      KAFKA_REPLICA_FETCH_MAX_BYTES: 10485760
    healthcheck:
      test: ["CMD", "kafka-topics", "--bootstrap-server", "localhost:9092", "--list"]
      interval: 30s
      timeout: 10s
      retries: 5
    depends_on:
      zookeeper:
        condition: service_healthy
    networks:
      - data-platform
    restart: unless-stopped

  # ===========================================================================
  # KAFKA UI
  # ===========================================================================
  kafka-ui:
    image: provectuslabs/kafka-ui:latest
    container_name: kafka-ui
    ports:
      - "8081:8080"
    environment:
      KAFKA_CLUSTERS_0_NAME: enterprise-cluster
      KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS: kafka:9092
      KAFKA_CLUSTERS_0_ZOOKEEPER: zookeeper:2181
    depends_on:
      kafka:
        condition: service_healthy
    networks:
      - data-platform
    restart: unless-stopped

  # ===========================================================================
  # POSTGRES (Airflow Metadata)
  # ===========================================================================
  postgres:
    image: postgres:15-alpine
    container_name: postgres
    hostname: postgres
    ports:
      - "5433:5432"
    environment:
      POSTGRES_USER: airflow
      POSTGRES_PASSWORD: airflow
      POSTGRES_DB: airflow
    volumes:
      - postgres-data:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U airflow"]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - data-platform
    restart: unless-stopped

  # ===========================================================================
  # REDIS (Airflow Celery Broker)
  # ===========================================================================
  redis:
    image: redis:7-alpine
    container_name: redis
    hostname: redis
    ports:
      - "6379:6379"
    volumes:
      - redis-data:/data
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - data-platform
    restart: unless-stopped

  # ===========================================================================
  # MINIO (S3-Compatible Storage)
  # ===========================================================================
  minio:
    image: minio/minio:latest
    container_name: minio
    hostname: minio
    ports:
      - "9000:9000"
      - "9001:9001"
    environment:
      MINIO_ROOT_USER: minioadmin
      MINIO_ROOT_PASSWORD: minioadmin123
    command: server /data --console-address ":9001"
    volumes:
      - minio-data:/data
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9000/minio/health/live"]
      interval: 30s
      timeout: 20s
      retries: 3
    networks:
      - data-platform
    restart: unless-stopped

  # ===========================================================================
  # MINIO CLIENT (Bucket Initialization)
  # ===========================================================================
  minio-init:
    image: minio/mc:latest
    container_name: minio-init
    depends_on:
      minio:
        condition: service_healthy
    entrypoint: >
      /bin/sh -c "
      mc alias set myminio http://minio:9000 minioadmin minioadmin123;
      mc mb myminio/bronze --ignore-existing;
      mc mb myminio/silver --ignore-existing;
      mc mb myminio/gold --ignore-existing;
      mc mb myminio/checkpoints --ignore-existing;
      mc mb myminio/features --ignore-existing;
      mc mb myminio/raw --ignore-existing;
      echo 'Buckets created successfully';
      exit 0;
      "
    networks:
      - data-platform

  # ===========================================================================
  # METABASE POSTGRES
  # ===========================================================================
  metabase-postgres:
    image: postgres:15-alpine
    container_name: metabase-postgres
    hostname: metabase-postgres
    environment:
      POSTGRES_USER: metabase
      POSTGRES_PASSWORD: metabase
      POSTGRES_DB: metabase
    volumes:
      - metabase-postgres-data:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U metabase"]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - data-platform
    restart: unless-stopped

  # ===========================================================================
  # METABASE (BI Tool)
  # ===========================================================================
  metabase:
    image: metabase/metabase:latest
    container_name: metabase
    hostname: metabase
    ports:
      - "3000:3000"
    environment:
      MB_DB_TYPE: postgres
      MB_DB_DBNAME: metabase
      MB_DB_PORT: 5432
      MB_DB_USER: metabase
      MB_DB_PASS: metabase
      MB_DB_HOST: metabase-postgres
    depends_on:
      metabase-postgres:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:3000/api/health"]
      interval: 30s
      timeout: 10s
      retries: 5
    networks:
      - data-platform
    restart: unless-stopped

  # ===========================================================================
  # PROMETHEUS
  # ===========================================================================
  prometheus:
    image: prom/prometheus:v2.47.0
    container_name: prometheus
    hostname: prometheus
    ports:
      - "9091:9090"
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--storage.tsdb.retention.time=15d'
      - '--web.console.libraries=/etc/prometheus/console_libraries'
      - '--web.console.templates=/etc/prometheus/consoles'
      - '--web.enable-lifecycle'
    volumes:
      - ../monitoring/prometheus/prometheus.yml:/etc/prometheus/prometheus.yml:ro
      - ../monitoring/prometheus/rules:/etc/prometheus/rules:ro
      - prometheus-data:/prometheus
    networks:
      - data-platform
    restart: unless-stopped

  # ===========================================================================
  # GRAFANA
  # ===========================================================================
  grafana:
    image: grafana/grafana:10.1.0
    container_name: grafana
    hostname: grafana
    ports:
      - "3001:3000"
    environment:
      GF_SECURITY_ADMIN_USER: admin
      GF_SECURITY_ADMIN_PASSWORD: admin
      GF_USERS_ALLOW_SIGN_UP: 'false'
      GF_SERVER_ROOT_URL: http://localhost:3001
    volumes:
      - ../monitoring/grafana/provisioning:/etc/grafana/provisioning:ro
      - ../monitoring/grafana/dashboards:/var/lib/grafana/dashboards:ro
      - grafana-data:/var/lib/grafana
    depends_on:
      - prometheus
    networks:
      - data-platform
    restart: unless-stopped

  # ===========================================================================
  # FASTAPI (REST API)
  # ===========================================================================
  api:
    build:
      context: ../api
      dockerfile: Dockerfile
    container_name: api
    hostname: api
    ports:
      - "8005:8000"
    environment:
      API_HOST: 0.0.0.0
      API_PORT: 8000
      KAFKA_BOOTSTRAP_SERVERS: kafka:9092
      REDIS_HOST: redis
      REDIS_PORT: 6379
      MINIO_ENDPOINT: minio:9000
      MINIO_ACCESS_KEY: minioadmin
      MINIO_SECRET_KEY: minioadmin123
    volumes:
      - ../api:/app
      - ../kafka:/app/kafka
      - delta-data:/data/delta
    depends_on:
      kafka:
        condition: service_healthy
      redis:
        condition: service_healthy
    networks:
      - data-platform
    restart: unless-stopped

  # ===========================================================================
  # PORTFOLIO WEBSITE (Next.js)
  # ===========================================================================
  website:
    build:
      context: ../website
      dockerfile: Dockerfile
    container_name: website
    hostname: website
    ports:
      - "3002:3000"
    environment:
      NEXT_PUBLIC_API_URL: http://api:8000
    volumes:
      - ../website:/app
      - /app/node_modules
      - /app/.next
    depends_on:
      - api
    networks:
      - data-platform
    restart: unless-stopped
